{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 users who have opted out from follow-ups.\n",
      "Loaded 2 users who have opted out from reminders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.5.0 of praw is outdated. Version 7.6.0 was released Tuesday May 10, 2022.\n"
     ]
    }
   ],
   "source": [
    "# STANDARD LIBRARY IMPORTS\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "# THIRD PARTY IMPORTS\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "# PROJECT IMPORTS\n",
    "from setup import reddit\n",
    "from settings import *\n",
    "from StickyThreadContent import *\n",
    "\n",
    "subreddit = reddit.subreddit(TARGET_SUBREDDIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 253 awards from the past two months\n"
     ]
    }
   ],
   "source": [
    "# load most recent 2 months worth of awards\n",
    "recent_awardsfiles = sorted(glob.glob( os.path.join(PATH_TO_STORE, TARGET_SUBREDDIT, 'awards*.csv') ), reverse=True)\n",
    "\n",
    "# last two files\n",
    "df = pd.concat([pd.read_csv(f) for f in recent_awardsfiles[:2]])\n",
    "\n",
    "print(f'Loaded {len(df):,d} awards from the past two months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 156 awards from the past 4 weeks.\n"
     ]
    }
   ],
   "source": [
    "# filter to recent WEEKLY_STICKY_THREAD_TIME_PERIOD weeks\n",
    "recency_threshold = datetime.datetime.utcnow() - datetime.timedelta(weeks=WEEKLY_STICKY_THREAD_TIME_PERIOD)\n",
    "df = df.loc[ df.awarding_timestamp > int(recency_threshold.timestamp()) ,:]\n",
    "\n",
    "print(f'Filtered to {len(df):,d} awards from the past {WEEKLY_STICKY_THREAD_TIME_PERIOD} weeks.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted awards for 120 users.\n",
      "Took top 3 users, considering ties.\n"
     ]
    }
   ],
   "source": [
    "# compute top awardees\n",
    "awardees = df.groupby('awarded_author').agg({'awarding_id':'count'}).iloc[:,0].sort_values(ascending=False)\n",
    "\n",
    "print(f'Counted awards for {len(awardees):,d} users.')\n",
    "\n",
    "# include more awardees in case of ties\n",
    "awardees = awardees.loc[ awardees >= awardees.iloc[NUM_TOP_AWARDEES-1] ]\n",
    "\n",
    "print(f'Took top {len(awardees):,d} users, considering ties.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add '/u/' to start of users, for formatting of reddit table\n",
    "awardees.index = '/u/' + awardees.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got top 3 threads with the most awards.\n"
     ]
    }
   ],
   "source": [
    "submissions = df.groupby('submission_id').agg({'awarding_id':'count'}).iloc[:,0].sort_values(ascending=False).iloc[:NUM_TOP_THREADS]\n",
    "print(f'Got top {NUM_TOP_THREADS:,d} threads with the most awards.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch submission titles and urls from the api\n",
    "\n",
    "def format_submission_link(prefixed_id):\n",
    "    submission = reddit.submission(id=prefixed_id[3:])\n",
    "    \n",
    "    try:\n",
    "        title = submission.title\n",
    "        link  = submission.permalink\n",
    "        return f'[{title}](https://reddit.com{link})'\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "submissions_formatted = map(format_submission_link, submissions.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching post titles for top threads, using the reddit API...Done.\n"
     ]
    }
   ],
   "source": [
    "print('Fetching post titles for top threads, using the reddit API...', end='')\n",
    "submissions.index = submissions_formatted\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 threads without titles.\n"
     ]
    }
   ],
   "source": [
    "print(f'Dropping {submissions.index.isnull().sum()} threads without titles.')\n",
    "submissions = submissions.loc[submissions.index.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reddit_table(s, header=None, align='--:|:--'):\n",
    "    '''\n",
    "    Given a pandas series, format a reddit table with two columns.\n",
    "    \n",
    "    The first column is the series index, the second column is the\n",
    "    series values.\n",
    "    \n",
    "    If header is provided, add a header row with the given values.\n",
    "    As reddit tables require a header, if none is given, a default\n",
    "    will be included.\n",
    "    \n",
    "    for align: :-- is left\n",
    "               :=: is center\n",
    "               --: is right\n",
    "    '''\n",
    "    assert isinstance(s, pd.Series)\n",
    "    if header is not None: assert len(header)==2\n",
    "        \n",
    "    rows = s.index + ' | ' + s.astype('str')\n",
    "    \n",
    "    if header is not None: \n",
    "        header = str(header[0]) + ' | ' + str(header[1])\n",
    "    else:\n",
    "        header = f'index | {s.name if s.name is not None else \"unnamed value\"}'\n",
    "    \n",
    "    return '\\n'.join([header, align]+rows.to_list())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "awardees    = format_reddit_table(awardees,\n",
    "                                  header=('Username', 'Points')\n",
    "                                 )\n",
    "\n",
    "submissions = format_reddit_table(submissions,\n",
    "                                  header=('Post Title', 'Awards Within')\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posting the discussion thread to /r/photocritique...Done.\n"
     ]
    }
   ],
   "source": [
    "# silence the deprecation warning\n",
    "reddit.validate_on_submit = True\n",
    "\n",
    "print(f'Posting the discussion thread to /r/{TARGET_SUBREDDIT}...', end='')\n",
    "thread = reddit.subreddit(TARGET_SUBREDDIT).submit(\n",
    "    title    = STICKY_TITLE,\n",
    "    selftext = STICKY_BODY.format(awardees, submissions)\n",
    ")\n",
    "\n",
    "thread.mod.distinguish()\n",
    "thread.mod.sticky(bottom=False)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pcbot] *",
   "language": "python",
   "name": "conda-env-pcbot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
